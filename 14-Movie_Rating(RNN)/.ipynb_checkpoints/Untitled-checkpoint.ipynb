{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train=pd.read_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=Train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=[]\n",
    "for i in range(X_train.shape[0]):\n",
    "    t=len(X_train[i].split())\n",
    "    length.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes=np.unique(length,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1033 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0,300)\n",
    "plt.ylim(0,1000)\n",
    "plt.bar(sizes[1],sizes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### so length of a sentence should be 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train=(data[:,1]=='pos')+0\n",
    "Y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove.txt',encoding='mbcs') as f:\n",
    "    doc=f.readlines()\n",
    "    \n",
    "glove_emb={\n",
    "          }\n",
    "for i in range(len(doc)):\n",
    "    word   = doc[i].split(\" \")[0]\n",
    "    vector = np.array(doc[i].split(\" \")[1:],dtype='float32')\n",
    "    \n",
    "    glove_emb[word]=vector    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_emb['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we will first convert this 40000 matrix into 40000,300 \n",
    "* And next  make a dictionary containing all unique words\n",
    "* Also make weight matrix for embeddding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "rg=RegexpTokenizer(\"[a-zA-Z]+\")\n",
    "sw=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mature intelligent and highly charged melodrama unbelivebly filmed in China in 1948. wei wei's stunning performance as the catylast in a love triangle is simply stunning if you have the oppurunity to see this magnificent film take it\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique={\n",
    "    }\n",
    "\n",
    "k=1;\n",
    "X_train=[]\n",
    "for i in range(X.shape[0]):\n",
    "    l=[]\n",
    "    words=rg.tokenize(X[i])\n",
    "    words=[w for w in words if w not in sw]\n",
    "    \n",
    "    for j in words:\n",
    "        if j.lower() in unique:\n",
    "            l.append(unique[j.lower()])\n",
    "            \n",
    "        else:\n",
    "            l.append(k)\n",
    "            unique[j.lower()]=k\n",
    "            k+=1   \n",
    "    X_train.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90654"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "X_train = sequence.pad_sequences(X_train,maxlen=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         9065400   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,314,361\n",
      "Trainable params: 9,314,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(90654,100))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      "  768/32000 [..............................] - ETA: 1:15:15 - loss: 0.6935 - acc: 0.4987"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train,Y_train,validation_split=.2,epochs=5,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making some changes to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train=pd.read_csv(\"Train.csv\")\n",
    "data=Train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=(data[:,1]=='pos')+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'pos', 'pos', ..., 'neg', 'pos', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83297"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique={\n",
    "    }\n",
    "\n",
    "weight=[]\n",
    "k=1;\n",
    "X_train=np.zeros((40000,300))\n",
    "for i in range(X.shape[0]):\n",
    "    words=rg.tokenize(X[i])\n",
    "    words=[w for w in words if w not in sw]\n",
    "    \n",
    "    for j in range(min(len(words),300)):\n",
    "        if words[j].lower() in unique:\n",
    "            X_train[i][j]=unique[words[j].lower()]\n",
    "            \n",
    "        else:\n",
    "            if words[j] in glove_emb:\n",
    "                weight.append(glove_emb[words[j]])\n",
    "                X_train[i][j]=k\n",
    "                unique[words[j].lower()]=k\n",
    "                k+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,     2,     3, ...,     0,     0,     0],\n",
       "       [   34,    35,    36, ...,     0,     0,     0],\n",
       "       [   83,    84,    85, ...,    29,   233,   234],\n",
       "       ...,\n",
       "       [  504,   122,   367, ...,     0,     0,     0],\n",
       "       [25163,    21,    18, ...,   131,   179,   101],\n",
       "       [  101,  1325,    29, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix=[np.zeros((50,))]+weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix=np.array(weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 50)           4164850   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300, 128)          91648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 4,392,276\n",
      "Trainable params: 4,392,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(46097,50, weights=[weight_matrix], input_length=200, trainable=False))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      " 9824/28000 [=========>....................] - ETA: 9:55 - loss: 0.6939 - acc: 0.5034"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-534dbdbdb561>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train,Y_train,validation_split=.3,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
